# ğŸ§  MLP - ImplementaÃ§Ã£o ProprietÃ¡ria de Rede Neural Multicamadas

## ğŸ“‹ DescriÃ§Ã£o do Projeto
Este projeto contÃ©m uma implementaÃ§Ã£o completa de um **Perceptron Multicamadas (MLP)** desenvolvida do zero em **R**, como parte de um trabalho de **iniciaÃ§Ã£o cientÃ­fica**.  
A implementaÃ§Ã£o inclui o algoritmo de **Backpropagation** para treinamento e Ã© comparada com pacotes estabelecidos do R.

---

## ğŸ¯ Objetivos

- Implementar um MLP funcional com backpropagation  
- Testar em problemas clÃ¡ssicos (XOR e Iris)  
- Comparar performance com implementaÃ§Ãµes existentes  
- Gerar anÃ¡lises grÃ¡ficas de performance  

---

## ğŸ“ Estrutura do Projeto
```
mlp-project/
â”œâ”€â”€ mlp.R # ImplementaÃ§Ã£o principal do MLP
â”œâ”€â”€ testXOR.R # Testes com dataset XOR
â”œâ”€â”€ testIRIS.R # Testes com dataset Iris
â”œâ”€â”€ compare.R # ComparaÃ§Ã£o com outros pacotes
â”œâ”€â”€ mlp_xor_comparison.pdf # Resultados XOR (gerado)
â”œâ”€â”€ mlp_iris_comparison.pdf # Resultados Iris (gerado)
â””â”€â”€ comparacao_implementacoes_fixed.pdf # ComparaÃ§Ã£o (gerado)
```
---

## ğŸš€ Funcionalidades Implementadas

### ğŸ”§ FunÃ§Ãµes Principais

- `mlp.create()` â€” Cria a arquitetura da rede neural  
- `mlp.forward()` â€” PropagaÃ§Ã£o direta (forward propagation)  
- `mlp.train()` â€” Treinamento com backpropagation  
- `mlp.predict()` â€” PrediÃ§Ã£o para novos dados  
- `mlp.accuracy()` â€” CÃ¡lculo de acurÃ¡cia  
- `fnet()` / `dfnet()` â€” FunÃ§Ã£o de ativaÃ§Ã£o sigmoidal e sua derivada  

---

## ğŸ“Š Testes Realizados

### Problema XOR â€” [2, 4, 1]
- Problema nÃ£o linearmente separÃ¡vel  
- Teste com mÃºltiplas seeds (42, 123, 456, 789, 999)  
- AnÃ¡lise de convergÃªncia e acurÃ¡cia  

### Dataset Iris â€” [4, 5, 3]
- ClassificaÃ§Ã£o multiclasse (3 espÃ©cies)  
- NormalizaÃ§Ã£o de features  
- CodificaÃ§Ã£o one-hot para saÃ­da  

### ComparaÃ§Ã£o com Pacotes do R
- **neuralnet** â€” Pacote tradicional para redes neurais  
- **RSNNS** â€” Stuttgart Neural Network Simulator  

---

## ğŸ“ˆ Resultados Destacados

### ğŸ¯ Performance do XOR
- Nossa implementaÃ§Ã£o: **100% de acurÃ¡cia**  
- ConvergÃªncia: ~2100 Ã©pocas (threshold 0.01)  
- Estabilidade: Consistente entre mÃºltiplas seeds  

### ğŸŒ¸ Performance do Iris
- Arquitetura: 4 entradas, 5 neurÃ´nios ocultos, 3 saÃ­das  
- AcurÃ¡cia: Resultados consistentes com diferentes inicializaÃ§Ãµes  
- NormalizaÃ§Ã£o: PrÃ©-processamento essencial para convergÃªncia  

---

## âš¡ ComparaÃ§Ã£o com Outras ImplementaÃ§Ãµes

- ImplementaÃ§Ã£o prÃ³pria mostra performance competitiva  
- Curvas de aprendizado consistentes  
- CÃ³digo mais transparente e educacional  

---

## ğŸ› ï¸ Como Usar

### InstalaÃ§Ã£o das DependÃªncias
```r
install.packages(c("ggplot2", "neuralnet", "RSNNS"))
ExecuÃ§Ã£o dos Testes
Teste com XOR
source("testXOR.R")

Teste com Iris
source("testIRIS.R")

ComparaÃ§Ã£o com outros pacotes
source("compare.R")
